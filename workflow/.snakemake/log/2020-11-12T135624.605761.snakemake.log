Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 36
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	decrease_zero_inflation
	2

[Thu Nov 12 13:56:24 2020]
rule decrease_zero_inflation:
    input: results/Metadata/SRR12845350.json, results/Metadata/SRR8094770.json, results/Rawdata/HTSeq_count/SRR12845350_genes.tsv, results/Rawdata/HTSeq_count/SRR8094770_genes.tsv, results/Rawdata/HTSeq_count/SRR12845350_transcripts.tsv, results/Rawdata/HTSeq_count/SRR8094770_transcripts.tsv
    output: results/Counts/9606_genes.tsv, results/Counts/9606_transcripts.tsv
    jobid: 1
    threads: 9

Activating conda environment: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/db72b297
[Thu Nov 12 13:56:33 2020]
Finished job 1.
1 of 2 steps (50%) done

[Thu Nov 12 13:56:33 2020]
localrule all:
    input: results/Counts/9606_genes.tsv
    jobid: 0

[Thu Nov 12 13:56:33 2020]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /home/kasper/Git_repositories/LiverDB/workflow/.snakemake/log/2020-11-12T135624.605761.snakemake.log
