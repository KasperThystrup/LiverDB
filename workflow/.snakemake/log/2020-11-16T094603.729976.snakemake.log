Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 36
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	2	STAR_align
	1	all
	2	count_reads
	2	fastqdump
	2	metadata
	2	srafetch
	2	tx_sort
	2	zero_intolerance
	15

[Mon Nov 16 09:46:03 2020]
rule metadata:
    output: results/Metadata/SRR8094770.json
    log: info/logs/SRR8094770.metadata.log
    jobid: 8
    benchmark: info/benchmark/SRR8094770.metadata.bench
    wildcards: sample=SRR8094770
    threads: 36

[Mon Nov 16 09:46:08 2020]
Finished job 8.
1 of 15 steps (7%) done

[Mon Nov 16 09:46:08 2020]
rule srafetch:
    input: results/Metadata/SRR8094770.json
    output: results/Rawdata/SRA/SRR8094770.sra
    log: info/logs/SRR8094770.srafetch.log
    jobid: 14
    benchmark: info/benchmark/SRR8094770.srafetch.bench
    wildcards: sample=SRR8094770

Activating conda environment: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/f0208fbb
[Mon Nov 16 09:46:28 2020]
Finished job 14.
2 of 15 steps (13%) done

[Mon Nov 16 09:46:28 2020]
rule fastqdump:
    input: results/Metadata/SRR8094770.json, results/Rawdata/SRA/SRR8094770.sra
    output: results/Rawdata/Fastq/SRR8094770_1.fastq, results/Rawdata/Fastq/SRR8094770_2.fastq
    log: info/logs/SRR8094770.fastqdump.log
    jobid: 12
    benchmark: info/benchmark/SRR8094770.fastqdump.bench
    wildcards: sample=SRR8094770

Activating conda environment: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/f0208fbb
Removing temporary output file results/Rawdata/SRA/SRR8094770.sra.
[Mon Nov 16 09:47:19 2020]
Finished job 12.
3 of 15 steps (20%) done

[Mon Nov 16 09:47:19 2020]
rule STAR_align:
    input: results/Metadata/SRR8094770.json, results/Rawdata/Fastq/SRR8094770_1.fastq, results/Rawdata/Fastq/SRR8094770_2.fastq
    output: results/Rawdata/Aligned/SRR8094770_Aligned.sortedByCoord.out.bam, results/Rawdata/Aligned/SRR8094770_Aligned.toTranscriptome.out.bam, results/Rawdata/Aligned/SRR8094770_Chimeric.out.junction, results/Rawdata/Aligned/SRR8094770_Log.final.out, results/Rawdata/Aligned/SRR8094770_Log.out, results/Rawdata/Aligned/SRR8094770_Log.progress.out, results/Rawdata/Aligned/SRR8094770_SJ.out.tab
    log: info/logs/SRR8094770.star_align.log
    jobid: 9
    benchmark: info/benchmark/SRR8094770.star_align.bench
    wildcards: sample=SRR8094770
    threads: 4

Activating conda environment: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/fd596e9f
Removing temporary output file results/Rawdata/Fastq/SRR8094770_1.fastq.
Removing temporary output file results/Rawdata/Fastq/SRR8094770_2.fastq.
Removing temporary output file results/Rawdata/Aligned/SRR8094770_Log.progress.out.
[Mon Nov 16 09:50:32 2020]
Finished job 9.
4 of 15 steps (27%) done

[Mon Nov 16 09:50:32 2020]
rule tx_sort:
    input: results/Metadata/SRR8094770.json, results/Rawdata/Aligned/SRR8094770_Aligned.toTranscriptome.out.bam
    output: results/Rawdata/Aligned/SRR8094770_Aligned.toTranscriptome.sortedByCoord.out.bam
    log: info/logs/SRR8094770.tx_sort.log
    jobid: 10
    benchmark: info/benchmark/SRR8094770.tx_sort.bench
    wildcards: sample=SRR8094770

Activating conda environment: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/4267c048
Removing temporary output file results/Rawdata/Aligned/SRR8094770_Aligned.toTranscriptome.out.bam.
[Mon Nov 16 09:50:35 2020]
Finished job 10.
5 of 15 steps (33%) done

[Mon Nov 16 09:50:35 2020]
rule count_reads:
    input: results/Metadata/SRR8094770.json, results/Rawdata/Aligned/SRR8094770_Aligned.sortedByCoord.out.bam, results/Rawdata/Aligned/SRR8094770_Aligned.toTranscriptome.sortedByCoord.out.bam
    output: results/Rawdata/Counts/9606/SRR8094770_genes.tsv, results/Rawdata/Counts/9606/SRR8094770_transcripts.tsv
    log: info/logs/9606.SRR8094770.count_reads.log
    jobid: 4
    benchmark: info/benchmark/9606.SRR8094770.count_reads.bench
    wildcards: species=9606, sample=SRR8094770

Activating conda environment: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/4267c048
Removing temporary output file results/Rawdata/Aligned/SRR8094770_Aligned.sortedByCoord.out.bam.
Removing temporary output file results/Rawdata/Aligned/SRR8094770_Aligned.toTranscriptome.sortedByCoord.out.bam.
[Mon Nov 16 09:53:53 2020]
Finished job 4.
6 of 15 steps (40%) done

[Mon Nov 16 09:53:53 2020]
rule zero_intolerance:
    input: results/Rawdata/Counts/9606/SRR8094770_genes.tsv, results/Rawdata/Counts/9606/SRR8094770_transcripts.tsv
    output: results/Filetered_counts/9606/Samples/SRR8094770_gene_count.tsv, results/Filetered_counts/9606/Samples/SRR8094770_transcript_count.tsv
    jobid: 2
    wildcards: species=9606, sample=SRR8094770
    threads: 4

Activating conda environment: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/db72b297
Waiting at most 5 seconds for missing files.
MissingOutputException in line 237 of /home/kasper/Git_repositories/LiverDB/workflow/Snakefile.py:
Job completed successfully, but some output files are missing. Missing files after 5 seconds:
results/Filetered_counts/9606/Samples/SRR8094770_gene_count.tsv
results/Filetered_counts/9606/Samples/SRR8094770_transcript_count.tsv
This might be due to filesystem latency. If that is the case, consider to increase the wait time with --latency-wait.
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/kasper/Git_repositories/LiverDB/workflow/.snakemake/log/2020-11-16T094603.729976.snakemake.log
