Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 36
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	zero_intolerance
	2

[Mon Nov 16 11:12:56 2020]
rule zero_intolerance:
    input: results/Rawdata/Counts/9606/SRR12845350_genes.tsv, results/Rawdata/Counts/9606/SRR12845350_transcripts.tsv
    output: results/Filetered_counts/9606/Samples/SRR12845350_gene_count.tsv, results/Filetered_counts/9606/Samples/SRR12845350_transcript_count.tsv
    jobid: 1
    wildcards: species=9606, sample=SRR12845350
    threads: 36

Activating conda environment: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/db72b297
[Mon Nov 16 11:13:03 2020]
Error in rule zero_intolerance:
    jobid: 1
    output: results/Filetered_counts/9606/Samples/SRR12845350_gene_count.tsv, results/Filetered_counts/9606/Samples/SRR12845350_transcript_count.tsv
    conda-env: /home/kasper/Git_repositories/LiverDB/.snakemake/conda/db72b297

RuleException:
CalledProcessError in line 252 of /home/kasper/Git_repositories/LiverDB/workflow/Snakefile.py:
Command 'source /home/kasper/miniconda3/bin/activate '/home/kasper/Git_repositories/LiverDB/.snakemake/conda/db72b297'; set -euo pipefail;  Rscript --vanilla /home/kasper/Git_repositories/LiverDB/.snakemake/scripts/tmpc36ynm82.zero_intolerance.R' returned non-zero exit status 1.
  File "/home/kasper/Git_repositories/LiverDB/workflow/Snakefile.py", line 252, in __rule_zero_intolerance
  File "/home/kasper/miniconda3/lib/python3.7/concurrent/futures/thread.py", line 57, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/kasper/Git_repositories/LiverDB/workflow/.snakemake/log/2020-11-16T111256.168227.snakemake.log
